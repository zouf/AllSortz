We acquired the academic dataset from yelp. The rating consists of ?? users and?? businesses. The businesses are all located in the vicinity of $30$ differentuniversities in the United States. There are a total of ?? ratings. We initiallymisunderstood the datasets. We thought we were obtaining two differentdatasets, one from Michigan and one from Princeton, but we actually recieved theentire dataset twice. Our initial plan was to get two different datasets,training on the first then finally testing on the second. Unfortunately weunknowingly trained on the entire body of data, so we weren't able to test onany fresh data. For our application, this isn't as big of a problem as others in practice. Thisis because in practice, we will be able to tune the model on the entire body ofdata fairly often. Because of our optimizations, tests run fairly quickly makingit possible to adjust the model fairly often. Keeping a set of fresh data totest on is important for situations where you wish to have a solution that willwork on all datasets without any need for tuning and that really isn't our goal.