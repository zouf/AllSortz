% talk about data

We acquired the academic dataset from Yelp\cite{yelp}. The rating consists of
\numUserTotal users and \numBusTotal businesses. The businesses are all located
in the vicinity of $30$ different universities in the United States. There are
a total of \numRatingTotal ratings. We initially misunderstood the datasets. We
believed, from the wording on the website, we were obtaining two different
datasets, one from Michigan and one from Princeton, but we actually received
the same dataset twice. Our initial plan was to get two different datasets,
training on the first then finally testing on the second. Unfortunately we
unknowingly trained on the entire body of data, so we weren't able to test on
any fresh data. 

As a replacement for two datasets, we partitioned our dataset into two; one set
including only businesses from California and one set with all other
businesses. 

%For our application, this isn't as big of a problem as others in practice. This
%is because in practice, we will be able to tune the model on the entire body of
%data fairly often. Because of our optimizations, tests run fairly quickly making
%it possible to adjust the model fairly often. Keeping a set of fresh data to
%test on is important for situations where you wish to have a solution that will
%work on all datasets without any need for tuning and that really isn't our goal.

